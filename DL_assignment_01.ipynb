{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puGbMcjaiIvW",
        "outputId": "2f2d7256-8f8a-46ab-f03b-807d0b4af828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 119s 732ms/step - loss: 0.6573 - accuracy: 0.6039 - val_loss: 0.5971 - val_accuracy: 0.6888\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 116s 741ms/step - loss: 0.6008 - accuracy: 0.6732 - val_loss: 0.6259 - val_accuracy: 0.6250\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 115s 736ms/step - loss: 0.5427 - accuracy: 0.7294 - val_loss: 0.5650 - val_accuracy: 0.7050\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 116s 737ms/step - loss: 0.4685 - accuracy: 0.7753 - val_loss: 0.5394 - val_accuracy: 0.7478\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 115s 736ms/step - loss: 0.4214 - accuracy: 0.8088 - val_loss: 0.5142 - val_accuracy: 0.7600\n",
            "196/196 [==============================] - 37s 188ms/step - loss: 0.4894 - accuracy: 0.7726\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 250s 2s/step - loss: 0.5107 - accuracy: 0.7273 - val_loss: 0.3310 - val_accuracy: 0.8586\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 245s 2s/step - loss: 0.2792 - accuracy: 0.8881 - val_loss: 0.3101 - val_accuracy: 0.8758\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 247s 2s/step - loss: 0.2250 - accuracy: 0.9120 - val_loss: 0.3351 - val_accuracy: 0.8680\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 248s 2s/step - loss: 0.1794 - accuracy: 0.9341 - val_loss: 0.4298 - val_accuracy: 0.8628\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 247s 2s/step - loss: 0.1441 - accuracy: 0.9489 - val_loss: 0.3914 - val_accuracy: 0.8728\n",
            "196/196 [==============================] - 92s 467ms/step - loss: 0.3951 - accuracy: 0.8712\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 326s 2s/step - loss: 0.4925 - accuracy: 0.7581 - val_loss: 0.3348 - val_accuracy: 0.8686\n",
            "Epoch 2/5\n",
            " 31/157 [====>.........................] - ETA: 3:46 - loss: 0.2827 - accuracy: 0.8919"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Set the maximum number of words to consider in the reviews\n",
        "max_words = 5000\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_length = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# Lists to store accuracy for each model\n",
        "accuracies = []\n",
        "\n",
        "# Models to compare\n",
        "model_names = [\"RNN\", \"GRU\", \"LSTM\"]\n",
        "\n",
        "models = [\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        SimpleRNN(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ]),\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        GRU(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ]),\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        LSTM(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Compile and train models\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "for model in models:\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "    _, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(epochs, accuracies)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Comparison of Recurrent Models for Sentiment Analysis')\n",
        "plt.ylim(0.8, 1.0)  # Adjust the y-axis limits as needed\n",
        "plt.show()"
      ]
    }
  ]
}